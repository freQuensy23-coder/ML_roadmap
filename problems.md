# Practical questions

### Похожие данные
Мы решаем задачу детекция токсичных коментариев. Мы с hf скачали датасет отзывов, на 300к примеров и на нем обучили берт. Плюс у нас есть 10 млн своих отзывов. Как без разметки понять норм ли такой подход, не упадут ли сильно метрики модели на наших данных, ведь они потенциально могут сильно отличаться от датасета HF

### Баес на пары слов
Мы обучаем берт на детектор токсичности на датасет из 290к трэин, 10к тест, классы близки к балансу. 

И мы обнаружили что у нас есть баес на некоторые пары слов. То есть если мы возьмем нетоксичный отзыв и добавим туда нетоксичное слово то модель посчитает отзыв токсичным. Как без разметки найти такие слова (которые при добавлении к обычному отзыву "токсичат его")

### Одна модель
Для обработки отзывов мы используем 3 модели - 

* bert + CRF для задачи NER
* bert + lineal для классификации положительный/отрицательный
* статистическую модель для нормализации слов

Таким образом из отзыва "вкусного борща"  первая модль достанет слово борщ, вторая классифицирует его как нейтральный а третья нормализует - "вкусный борщ"

Вопрос - как решить эти 3 задачи за 1 проход одной моделью (без ансамблей)?
