1. Создание BASE модели - учим на большом количестве сырых данных из интерната, в формате Causal LM. Учим модель общим представлениям о мире.
1. Создание chat/instruct модели - дообучаем модель на диалогах/инструкциях, превращая ее из статистического попугая в ИИ-помощника
1. alignment (RLHF) - закладываение в модель "правил хорошего поведения", обычно делается через RLHF. В ней учат модель тому, что рассказать пользователю как сделать бомбу/произвести химоружие - плохо
   Можно обойтись без 3го - если нас устроит "не зацензуреная" модель, без 3го и 2го шагов, если нам нужна базовая модель например что бы ее превратить в ревард модель/сентимент анализатор/затюнить под супер специфичную задачу, и четкий формат промпта будет мешать
